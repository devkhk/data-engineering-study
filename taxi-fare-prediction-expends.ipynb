{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89c9cd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6138f5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/08 00:31:38 WARN Utils: Your hostname, devkhk-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 172.30.1.27 instead (on interface en0)\n",
      "22/04/08 00:31:38 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/08 00:31:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# parquet 압축 코덱 선택, defalut:\"snappy\"\n",
    "MAX_MEMORY = \"5g\"\n",
    "spark = SparkSession.builder.appName(\"taxi-fare-prediction\")\\\n",
    "            .config(\"spark.executor.memory\", MAX_MEMORY)\\\n",
    "            .config(\"spark.driver.memory\", MAX_MEMORY)\\\n",
    "            .config(\"spark.sql.parquet.compression.codec\", None)\\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba08e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_files = \"/Users/devkhk/Documents/data-engineering-study/data/trips/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39931f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "trips_df = spark.read.csv(f\"file:///{trip_files}\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32798b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed8cbf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.createOrReplaceTempView(\"trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "df30a2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    passenger_count,\n",
    "    PULocationID as pickup_location_id,\n",
    "    DOLocationID as dropoff_location_id,\n",
    "    trip_distance,\n",
    "    HOUR(tpep_pickup_datetime) as pickup_time,\n",
    "    DATE_FORMAT(TO_DATE(tpep_pickup_datetime), 'EEEE') as day_of_week,\n",
    "    total_amount\n",
    "FROM\n",
    "    trips\n",
    "WHERE\n",
    "    total_amount < 5000\n",
    "    AND total_amount > 0\n",
    "    AND trip_distance > 0\n",
    "    AND trip_distance < 500\n",
    "    AND passenger_count < 4\n",
    "    AND TO_DATE(tpep_pickup_datetime) >= '2021-01-01'\n",
    "    AND TO_DATE(tpep_pickup_datetime) < '2021-08-01'\n",
    "\"\"\"\n",
    "\n",
    "data_df = spark.sql(query)\n",
    "data_df.createOrReplaceTempView('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dccae791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+\n",
      "|passenger_count|pickup_location_id|dropoff_location_id|trip_distance|pickup_time|day_of_week|total_amount|\n",
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+\n",
      "|              0|               138|                265|         16.5|          0|     Monday|       70.07|\n",
      "|              1|                68|                264|         1.13|          0|     Monday|       11.16|\n",
      "|              1|               239|                262|         2.68|          0|     Monday|       18.59|\n",
      "|              1|               186|                 91|         12.4|          0|     Monday|        43.8|\n",
      "|              2|               132|                265|          9.7|          0|     Monday|        32.3|\n",
      "|              1|               138|                141|          9.3|          0|     Monday|       43.67|\n",
      "|              1|               138|                 50|         9.58|          0|     Monday|        46.1|\n",
      "|              1|               132|                123|         16.2|          0|     Monday|        45.3|\n",
      "|              1|               140|                  7|         3.58|          0|     Monday|        19.3|\n",
      "|              1|               239|                238|         0.91|          0|     Monday|        14.8|\n",
      "|              2|               116|                 41|         2.57|          0|     Monday|        12.8|\n",
      "|              1|                74|                 41|          0.4|          0|     Monday|         5.3|\n",
      "|              1|               239|                144|         3.26|          0|     Monday|        17.3|\n",
      "|              1|               132|                 91|        13.41|          0|     Monday|       47.25|\n",
      "|              2|               132|                230|         18.3|          0|     Monday|       61.42|\n",
      "|              1|               229|                 48|         1.53|          0|     Monday|       14.16|\n",
      "|              1|                48|                 68|          2.0|          0|     Monday|        11.8|\n",
      "|              2|               132|                255|         16.6|          0|     Monday|       54.96|\n",
      "|              1|               132|                145|         15.5|          0|     Monday|       56.25|\n",
      "|              2|                79|                164|          1.3|          0|     Monday|        16.8|\n",
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4c4d0f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- pickup_location_id: integer (nullable = true)\n",
      " |-- dropoff_location_id: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- pickup_time: integer (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05e18876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석할 데이터 테이블이 준비 되었으면 학습용, 테스트용 데이터로 나눈다.\n",
    "train_df, test_df = data_df.randomSplit([.8, .2], seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1ee03b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *학습용 데이터를 꺼내 쓸 수 있도록 저장하기\n",
    "data_dir = \"/Users/devkhk/Documents/data-engineering-study/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2ee5e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_df.write.format(\"parquet\").save(f\"{data_dir}/train/\")\n",
    "test_df.write.format(\"parquet\").save(f\"{data_dir}/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d43b2ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 parquet 불러오기\n",
    "train_df = spark.read.parquet(f\"{data_dir}/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fb88960",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = spark.read.parquet(f\"{data_dir}/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7c64a1d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- pickup_location_id: integer (nullable = true)\n",
      " |-- dropoff_location_id: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- pickup_time: integer (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4e1c35c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot Encoding : Wednesday -> 4 -> [0,0,0,1,0,0,0]\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "cat_feats = [\n",
    "    \"pickup_location_id\",\n",
    "    \"dropoff_location_id\",\n",
    "    \"day_of_week\"\n",
    "]\n",
    "\n",
    "stages = []\n",
    "\n",
    "for c in cat_feats:\n",
    "    cat_indexer = StringIndexer(inputCol=c, outputCol= c + \"_idx\").setHandleInvalid(\"keep\")\n",
    "    onehot_encoder = OneHotEncoder(inputCols=[cat_indexer.getOutputCol()], outputCols=[c + \"_onehot\"])\n",
    "    stages += [cat_indexer, onehot_encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "75a408a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_62739c332208,\n",
       " OneHotEncoder_a5d8b7e8a003,\n",
       " StringIndexer_cdf76a70e9c2,\n",
       " OneHotEncoder_2b9708de83da,\n",
       " StringIndexer_beabeb2d762c,\n",
       " OneHotEncoder_db23d22fd30a]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "42f7f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "\n",
    "num_feats = [\n",
    "    \"passenger_count\",\n",
    "    \"trip_distance\",\n",
    "    \"pickup_time\"\n",
    "]\n",
    "\n",
    "for n in num_feats:\n",
    "    num_assembler = VectorAssembler(inputCols=[n], outputCol= n + \"_vector\")\n",
    "    num_scalar = StandardScaler(inputCol=num_assembler.getOutputCol(), outputCol= n + \"_scaled\")\n",
    "    stages += [num_assembler, num_scalar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1bd8850e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_62739c332208,\n",
       " OneHotEncoder_a5d8b7e8a003,\n",
       " StringIndexer_cdf76a70e9c2,\n",
       " OneHotEncoder_2b9708de83da,\n",
       " StringIndexer_beabeb2d762c,\n",
       " OneHotEncoder_db23d22fd30a,\n",
       " VectorAssembler_67b7c1afca8d,\n",
       " StandardScaler_e62b93e63109,\n",
       " VectorAssembler_909c188d7d37,\n",
       " StandardScaler_2ea98e00b5cc,\n",
       " VectorAssembler_e60e636f94ff,\n",
       " StandardScaler_3ff998f87394]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9107ce34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pickup_location_id_onehot',\n",
       " 'dropoff_location_id_onehot',\n",
       " 'day_of_week_onehot',\n",
       " 'passenger_count_scaled',\n",
       " 'trip_distance_scaled',\n",
       " 'pickup_time_scaled']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler_input = [c + \"_onehot\" for c in cat_feats] + [n + \"_scaled\" for n in num_feats]\n",
    "assembler_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0d8b46fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=assembler_input, outputCol=\"feature_vector\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6bc38fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_62739c332208,\n",
       " OneHotEncoder_a5d8b7e8a003,\n",
       " StringIndexer_cdf76a70e9c2,\n",
       " OneHotEncoder_2b9708de83da,\n",
       " StringIndexer_beabeb2d762c,\n",
       " OneHotEncoder_db23d22fd30a,\n",
       " VectorAssembler_67b7c1afca8d,\n",
       " StandardScaler_e62b93e63109,\n",
       " VectorAssembler_909c188d7d37,\n",
       " StandardScaler_2ea98e00b5cc,\n",
       " VectorAssembler_e60e636f94ff,\n",
       " StandardScaler_3ff998f87394,\n",
       " VectorAssembler_a9fb3e6a3d41]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dd18df41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "00bc7769",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "transform_stages = stages\n",
    "pipeline = Pipeline(stages=transform_stages)\n",
    "fitted_transformer = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1ee2fc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtrain_df = fitted_transformer.transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "112999fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(\n",
    "        maxIter=50,\n",
    "        solver=\"normal\",\n",
    "        labelCol=\"total_amount\",\n",
    "        featuresCol=\"feature_vector\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9c109371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/08 01:23:39 WARN Instrumentation: [b2a48522] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/04/08 01:23:59 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/04/08 01:23:59 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "22/04/08 01:24:13 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "22/04/08 01:24:13 WARN Instrumentation: [b2a48522] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n",
      "22/04/08 01:24:13 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "22/04/08 01:24:13 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = lr.fit(vtrain_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "92209f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtest_df = fitted_transformer.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0b9b2624",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(vtest_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9a7eb66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[passenger_count: int, pickup_location_id: int, dropoff_location_id: int, trip_distance: double, pickup_time: int, day_of_week: string, total_amount: double, pickup_location_id_idx: double, pickup_location_id_onehot: vector, dropoff_location_id_idx: double, dropoff_location_id_onehot: vector, day_of_week_idx: double, day_of_week_onehot: vector, passenger_count_vector: vector, passenger_count_scaled: vector, trip_distance_vector: vector, trip_distance_scaled: vector, pickup_time_vector: vector, pickup_time_scaled: vector, feature_vector: vector, prediction: double]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "828d5423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+------------+------------------+\n",
      "|day_of_week|trip_distance|total_amount|        prediction|\n",
      "+-----------+-------------+------------+------------------+\n",
      "|    Tuesday|          1.0|       10.55|12.695522792729275|\n",
      "|   Saturday|          1.7|        13.3| 14.45055801477692|\n",
      "|     Friday|          4.1|        21.3|21.108271361254214|\n",
      "|     Sunday|         11.5|        41.3| 40.87993984204375|\n",
      "|   Saturday|          1.7|       14.15| 13.90693298261399|\n",
      "|  Wednesday|          0.7|         5.8|  9.62248222618894|\n",
      "|  Wednesday|          5.0|        24.3|21.147909957146926|\n",
      "|   Thursday|          1.5|         8.8| 9.969750900636763|\n",
      "|     Monday|         13.4|       66.35| 62.65097273030503|\n",
      "|     Monday|         15.0|       70.67| 66.37330532523579|\n",
      "|  Wednesday|         14.2|       85.65| 89.80098581271078|\n",
      "|  Wednesday|          0.1|        55.3|12.483544948638677|\n",
      "|    Tuesday|          3.9|       21.95|23.136774384461823|\n",
      "|   Thursday|          4.7|        27.8| 23.06253705950276|\n",
      "|   Thursday|          1.4|       21.12|15.791556867253746|\n",
      "|   Thursday|          1.6|       13.55| 16.66388464261349|\n",
      "|   Thursday|          4.0|        20.8| 21.36982589020375|\n",
      "|  Wednesday|          4.3|       21.05| 21.84988605314538|\n",
      "|   Thursday|          4.9|        21.3|23.491569972722782|\n",
      "|  Wednesday|          2.4|       16.55|17.843846452773935|\n",
      "+-----------+-------------+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select([\"day_of_week\",\"trip_distance\", \"total_amount\", \"prediction\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d25a09f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.6485201652667625"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8d04e6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80849012500813"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "84d11997",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced338d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
