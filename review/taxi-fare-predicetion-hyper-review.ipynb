{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7c65f07",
   "metadata": {},
   "source": [
    "## 예측 모델 정확도 올리기 위해 다른 변수들을 추가해서 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0ca4bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb233f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/21 18:13:18 WARN Utils: Your hostname, devkhk-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 172.30.1.27 instead (on interface en0)\n",
      "22/04/21 18:13:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/21 18:13:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "MAX_MEMORY = \"5g\"\n",
    "spark = SparkSession.builder.appName(\"taxi-fare-prediction-expands\")\\\n",
    "                            .config(\"spark.executor.memory\", MAX_MEMORY)\\\n",
    "                            .config(\"spark.driver.memory\", MAX_MEMORY)\\\n",
    "                            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c3428d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parquet형태 저장\n",
    "data_dir = \"/Users/devkhk/Documents/data-engineering-study/data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8892732f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# parqeut 불러오기\n",
    "train_df = spark.read.parquet(f\"file:///{data_dir}train-review/\")\n",
    "test_df = spark.read.parquet(f\"file:///{data_dir}test-review/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2e5176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51e9a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카테고리 / Numberic Feature 분류 => pipeline stages 만들기\n",
    "stages = []\n",
    "\n",
    "cat_features = [\n",
    "    \"pickup_location_id\",\n",
    "    \"dropoff_location_id\",\n",
    "    \"hour\",\n",
    "    \"day_of_week\"\n",
    "]\n",
    "\n",
    "num_features = [\n",
    "    \"passenger_count\",\n",
    "    \"trip_distance\",\n",
    "]\n",
    "\n",
    "for c in cat_features:\n",
    "    cat_indexer = StringIndexer(inputCol=c, outputCol= c + \"_idx\").setHandleInvalid(\"keep\")\n",
    "    one_encoder = OneHotEncoder(inputCol=cat_indexer.getOutputCol(), outputCol= c + \"_onehot\")\n",
    "    stages += [cat_indexer, one_encoder]\n",
    "\n",
    "for n in num_features:\n",
    "    num_vector = VectorAssembler(inputCols=[n], outputCol= n + \"_vector\")\n",
    "    num_std = StandardScaler(inputCol=num_vector.getOutputCol(), outputCol=n + \"_std\")\n",
    "    stages += [num_vector, num_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19aa0100",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = [c+\"_onehot\" for c in cat_features] + [n + \"_std\" for n in num_features]\n",
    "vassembler = VectorAssembler(inputCols=assembler, outputCol=\"features\")\n",
    "stages += [vassembler]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227a32d9",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22a9e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9bba76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 튜닝은 데이터가 너무 크면 오래 걸리므로 적당한 toy_df를 sampling해줘야한다.\n",
    "toy_df = train_df.sample(True, 0.1, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "235da771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- pickup_location_id: integer (nullable = true)\n",
      " |-- dropoff_location_id: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day_of_week: integer (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "toy_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "660f0d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(\n",
    "    maxIter=30,\n",
    "    solver='normal',\n",
    "    labelCol=\"total_amount\",\n",
    ")\n",
    "cv_stages = stages + [lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72d8a269",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = ParamGridBuilder()\\\n",
    "                    .addGrid(lr.elasticNetParam, [.1, .2, .3, .4, .5])\\\n",
    "                    .addGrid(lr.regParam,[.01, .02, .03, .04, .05])\\\n",
    "                    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c31ceec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_pipeline = Pipeline(stages=cv_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c643f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(\n",
    "    estimator=cv_pipeline,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=RegressionEvaluator(labelCol=\"total_amount\"),\n",
    "    numFolds=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a762620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/21 18:55:41 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/04/21 18:55:41 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "22/04/21 18:55:43 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "22/04/21 18:55:43 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cv_model = cv.fit(toy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d9e4de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameter를 얻는다. \n",
    "alpha = cv_model.bestModel.stages[-1]._java_obj.getElasticNetParam()\n",
    "reg_parm = cv_model.bestModel.stages[-1]._java_obj.getRegParam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb884c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c062ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = lr = LinearRegression(\n",
    "    maxIter=30,\n",
    "    elasticNetParam=alpha,\n",
    "    regParam=reg_parm,\n",
    "    solver='normal',\n",
    "    labelCol=\"total_amount\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e9e1947",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d6b8687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "transformer = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab444a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtrain_df = transformer.transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e80b382e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = lr.fit(vtrain_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb16333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtest_df = transformerformer.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7073284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(vtest_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3c37cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- pickup_location_id: integer (nullable = true)\n",
      " |-- dropoff_location_id: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day_of_week: integer (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- pickup_location_id_idx: double (nullable = false)\n",
      " |-- pickup_location_id_onehot: vector (nullable = true)\n",
      " |-- dropoff_location_id_idx: double (nullable = false)\n",
      " |-- dropoff_location_id_onehot: vector (nullable = true)\n",
      " |-- hour_idx: double (nullable = false)\n",
      " |-- hour_onehot: vector (nullable = true)\n",
      " |-- day_of_week_idx: double (nullable = false)\n",
      " |-- day_of_week_onehot: vector (nullable = true)\n",
      " |-- passenger_count_vector: vector (nullable = true)\n",
      " |-- passenger_count_std: vector (nullable = true)\n",
      " |-- trip_distance_vector: vector (nullable = true)\n",
      " |-- trip_distance_std: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b80caada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|total_amount|        prediction|\n",
      "+------------+------------------+\n",
      "|        12.3|14.522882130200006|\n",
      "|       23.15|19.761763709280743|\n",
      "|        16.3|16.895246125594852|\n",
      "|         5.8| 9.051188847590547|\n",
      "|        65.3|   46.011215010444|\n",
      "|        13.3| 47.20738990668044|\n",
      "|        17.8| 49.01962796688548|\n",
      "|        76.3| 68.24258234983881|\n",
      "|        17.3|19.743503253461622|\n",
      "|        24.3|27.466475017600615|\n",
      "|       27.35| 25.72265257589921|\n",
      "|       32.75|29.928878940094307|\n",
      "|         8.8|12.294447521574881|\n",
      "|        12.8|16.950455884490687|\n",
      "|        15.8|17.564126318254218|\n",
      "|       20.75|20.505773970449674|\n",
      "|        20.3| 22.09136579049914|\n",
      "|       19.56| 17.82913196009853|\n",
      "|        24.3|23.004838152456742|\n",
      "|         8.3|13.235918828146922|\n",
      "+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select([\"total_amount\", \"prediction\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9b6b1eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.624055358189599"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "311a74fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8101430588034768"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63528ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
